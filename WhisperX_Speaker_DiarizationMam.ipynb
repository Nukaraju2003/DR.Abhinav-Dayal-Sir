{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nukaraju2003/DR.Abhinav-Dayal-Sir/blob/main/WhisperX_Speaker_DiarizationMam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rYFRH0R9GHiO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvNEfr0QCM3Y"
      },
      "outputs": [],
      "source": [
        "!pip install --q git+https://github.com/m-bain/whisperx.git\n",
        "!pip install git+https://github.com/m-bain/whisperx.git --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3r_VefNPjIS",
        "outputId": "d7ac85eb-f738-4b29-9a40-377435304425"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisperx\n",
        "device = \"cuda\"\n",
        "\n",
        "model = whisperx.load_model(\"large-v2\", device)\n",
        "# model = whisperx.load_model(\"large\", device)\n",
        "# model = whisperx.load_model(\"medium\", device)\n",
        "# model = whisperx.load_model(\"small\", device)\n",
        "result = model.transcribe(\"/content/drive/MyDrive/Jyothi Mam/student1.wav\")        # use your audio file\n",
        "transcribed_text = [segment[\"text\"] for segment in result[\"segments\"]]\n",
        "print(transcribed_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RC71yDJG0UBI",
        "outputId": "8ea55fae-615a-4e6e-9fee-5a238fc06880"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.1.2. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.0. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.1.0+cu118. Bad things might happen unless you revert torch to 1.x.\n",
            "Detected language: en (0.66) in first 30s of audio...\n",
            "[\" Tell me about yourself. Good afternoon, ma'am. I'm Thadala Veerabargiri from West Godavari. Currently, I'm pursuing my B.Tech final year in Vishnu Institute of Technology with CGPA 9.12. I have completed my intermediate in Sasi Junior College with 96% and I completed my 10th with 93% in Nagarjuna School.\", \" Coming to my family, my family includes my father, who is horticulturist, my mother, who is homemaker, and my sister currently pursuing her intermediate. And I love playing badminton. I have good knowledge in Java and Python, and I'm also interested in machine learning. I have completed two decent projects called screen recording application using Python and exploratory data analysis on engineering placements.\", ' What is your role in projects? My role is developing the application map. Like what technologies you have used for development of your projects? I have used libraries like NumPy, Pandas and OpenCD. Technology in the sense you should mention which programming language you have used. I have used Python.', \" Okay, is growing of technology is good for human or not? Yes ma'am, growing of technology is good for human in one way and in other way it leads to some consequences ma'am, like data security is not possible if we have more technology ma'am.\", \" And you said that you are interested in machine learning. Yes, ma'am. Like every person can be replaced by an artificial machine. Then what is your opinion on that? It is a boon for people having any disabilities, ma'am. But in some way, it leads to unemployment, ma'am. OK. Would you prefer hard work or smart work?\", \" I prefer both which is suitable to condition. Try to elaborate it with an example at least. Like if we want to achieve something we need some patience and in that time we need hard work ma'am. But in multitasking we use smart work. What made you to choose IT sector? IT sector is growing ma'am.\", \" Every day we have new technology and we can learn new things. Are you interested for relocation of your job? Yes, ma'am. Are you comfortable with rotational shifts like day shift and night shift? Yes, ma'am. I will be comfortable with rotational shifts. Okay, let's move with the technical side. Explain about OOP concepts. OOP is an object-oriented programming.\", ' which we can store the data in the form of objects and classes and it has four main principles like extraction, polymorphism, inheritance and encapsulation. What is the difference between union and structure in C language? Right now, I do not know the exact answer. I have only, I have know only the basics of C language.', ' What is a static variable? Static variable can be used for 3 types, it can be used for class, method and variable. If we use static for variable, the variable cannot be changed and if we use static for method, the method cannot be overridden and if we use it as a class, the class cannot be inherited.', ' What are different aggregation functions in SQL? Max, min, sum, count. Can you explain about descending order in SQL? How we can implement descending order? We can implement by using it in group by. By using a keyword.', ' What is normalization? Normalization is dividing tables into small tables which can be decomposed form. What is data redundancy? Data redundancy is having multiple copies. What is the second normal form?', ' Explain about inheritance and its types. Inheritance is the situation when child class inherits the properties from the parent class. Inheritance types are multiple inheritance, multilevel inheritance, single inheritance, hybrid inheritance. Whether Python support all types of inheritance like Java?', \" Java does not support all types of inheritance ma'am, but Python supports all types of inheritance. What is a constructor? Constructor is nothing but a instance of class which can have same name of class and it does not contain any return type. Ok. Can you explain me the logic for string reverse, implementation of string reverse? Yes ma'am.\", \" It is like minus index ma'am, we use column, column minus 1. Explain polymorphism with real life examples. Polymorphism means having many forms ma'am. For example, water ma'am, water has many forms, it is like solid, gas and liquid. What is the use of final keyword in Java?\", ' What is a strong number? Strong number means the sum of factorial of given digits of a number is equal to the given number. Where do you want to watch yourself in the next 5 years? I want to become a software professional. Do you have any role model?', ' I have role model Abdul Kalam. Why? Because from childhood he faced many challenges and although he can be successful in his life. Okay, fine.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **WhisperX_Speaker_Diarization**\n",
        "***  The provided code utilizes the WhisperX library to transcribe an audio file into text segments, aligns these segments by speakers, then groups continuous segments spoken by the same speaker. It extracts and organizes the continuous text segments for 'SPEAKER_01' and 'SPEAKER_02' speakers separately, saving them into a CSV file with distinct columns for each speaker's continuous text. ***"
      ],
      "metadata": {
        "id": "OySvjm_kFNWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisperx\n",
        "import pandas as pd\n",
        "\n",
        "device = \"cuda\"\n",
        "audio_file = \"/content/drive/MyDrive/Jyothi Mam/student1.wav\"     # use your audio file\n",
        "batch_size = 16\n",
        "compute_type = \"float16\"\n",
        "\n",
        "# 1. Transcribe audio with WhisperX\n",
        "model = whisperx.load_model(\"large-v2\", device, compute_type=compute_type)      #you can give your model name\n",
        "audio = whisperx.load_audio(audio_file)\n",
        "result = model.transcribe(audio, batch_size=batch_size)\n",
        "\n",
        "# 2. Align Whisper output\n",
        "model_a, metadata = whisperx.load_align_model(language_code=result[\"language\"], device=device)\n",
        "result = whisperx.align(result[\"segments\"], model_a, metadata, audio, device, return_char_alignments=False)\n",
        "\n",
        "# 3. Diarization to assign speaker labels\n",
        "diarize_model = whisperx.DiarizationPipeline(use_auth_token=\"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\", device=device)    #use yourhugging face token\n",
        "diarize_segments = diarize_model(audio)\n",
        "result = whisperx.assign_word_speakers(diarize_segments, result)\n",
        "\n",
        "# Group continuous segments by speaker\n",
        "speaker_texts = {\"SPEAKER_01\": [], \"SPEAKER_02\": []}\n",
        "current_speaker = None\n",
        "current_text = \"\"\n",
        "\n",
        "for segment in result[\"segments\"]:\n",
        "    speaker_id = segment[\"speaker\"]\n",
        "    text = segment[\"text\"]\n",
        "\n",
        "    if speaker_id == current_speaker:\n",
        "        current_text += text + \" \"\n",
        "    else:\n",
        "        if current_speaker is not None:\n",
        "            speaker_texts[current_speaker].append(current_text.strip())\n",
        "        current_speaker = speaker_id\n",
        "        current_text = text + \" \"\n",
        "\n",
        "# Append the last segment's text for the current speaker\n",
        "if current_speaker is not None:\n",
        "    speaker_texts[current_speaker].append(current_text.strip())\n",
        "\n",
        "# Create a DataFrame for each speaker\n",
        "speaker_01_df = pd.DataFrame({\"SPEAKER_01_text\": speaker_texts[\"SPEAKER_01\"]})\n",
        "speaker_02_df = pd.DataFrame({\"SPEAKER_02_text\": speaker_texts[\"SPEAKER_02\"]})\n",
        "\n",
        "# Save speaker texts to a single CSV file with separate columns for each speaker\n",
        "merged_df = pd.concat([speaker_01_df, speaker_02_df], axis=1)\n",
        "merged_df.to_csv('/content/drive/MyDrive/Jyothi Mam/speakers_continuous_text.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3wk-hlIDe_Q",
        "outputId": "ce8d7a76-f199-488e-c313-a84226cf64fe"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.1.2. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.0. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.1.0+cu118. Bad things might happen unless you revert torch to 1.x.\n",
            "Detected language: en (0.66) in first 30s of audio...\n"
          ]
        }
      ]
    }
  ]
}